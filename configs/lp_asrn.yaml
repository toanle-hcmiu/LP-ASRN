# LP-ASRN Configuration
# Layout-Aware and Character-Driven Super-Resolution Network

model:
  # Number of RRDB-EA blocks in the deep feature extractor
  # Full 16 blocks for maximum accuracy (A100 80GB can handle it)
  num_rrdb_blocks: 16

  # Number of feature channels
  num_filters: 64

  # Upscaling factor (2 for 2x, 4 for 4x)
  # Paper 2 uses 2x which achieved 49.8% recognition rate
  upscale_factor: 2

  # Use deformable convolutions in attention modules
  use_deformable: true

data:
  # Scenarios to include in training
  scenarios:
    - "Scenario-A"  # Light degradation
    - "Scenario-B"  # Heavy degradation

  # Layouts to include
  layouts:
    - "Brazilian"   # LLLNNNN pattern
    - "Mercosur"    # LLLNLNN pattern

  # Target size for LR images (height, width)
  # Increased from 17x31 to 34x62 (2x) for better OCR - each character now ~10-12 pixels instead of ~5-6
  lr_size: [34, 62]

  # Batch size for training (reduced from 128 to 32 due to 4x larger images)
  batch_size: 32

  # Number of data loading workers (reduced for DDP stability)
  num_workers: 4

  # Validation split
  val_split: 0.05

training:
  # Number of training epochs
  epochs: 100

  # Learning rate
  lr: 0.0001

  # Validation interval (validate every N epochs to save time)
  val_interval: 5  # Validate more frequently for better monitoring

  # Beam width for validation (higher = more accurate but slower)
  val_beam_width: 5

  # Adam optimizer betas
  beta1: 0.9
  beta2: 0.999

  # Gradient clipping for stability (prevents exploding gradients)
  gradient_clip: 1.0

  # StepLR learning rate schedule
  # Reduces LR by this factor every lr_step_size epochs
  # Paper 2 uses this to prevent oscillations
  lr_scheduler: "StepLR"
  lr_step_size: 5
  lr_gamma: 0.9

  # Early stopping patience (from Paper 1)
  # Stops after 30 epochs without improvement (increased for 98% target)
  early_stop_patience: 30

  # Monitor metric for early stopping
  # "recognition_rate" monitors OCR accuracy (Paper 2 innovation)
  # "loss" monitors total loss
  monitor_metric: "recognition_rate"

  # Output directory for all training outputs (checkpoints, logs, etc.)
  # Auto-formatted with timestamp at runtime: outputs/run_YYYYMMDD_HHMMSS
  save_dir: "outputs/run_%Y%m%d_%H%M%S"

loss:
  # Weight for LCOFL loss (character-driven loss)
  lambda_lcofl: 1.0

  # Weight for layout penalty
  lambda_layout: 0.5

  # Weight for SSIM loss (from Paper 2)
  lambda_ssim: 0.2

  # Confusion weight increment (added to confused character weights)
  alpha: 0.1

  # Layout penalty value (for each digit/letter mismatch)
  beta: 1.0

ocr:
  # OCR model type
  model_type: "parseq"

  # Pre-trained model path (HuggingFace model ID or local path)
  pretrained_path: "baudm/parseq-base"

  # Fine-tune Parseq on HR images before SR training
  finetune_first: true

  # Path to fine-tuned model (after fine-tuning)
  finetuned_path: "checkpoints/parseq/best.pth"

  # Keep OCR frozen during SR training (critical for stability)
  freeze_ocr: true

  # Maximum sequence length for OCR
  max_length: 7

  # Character vocabulary
  vocab: "0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ"

# Progressive Training Configuration
progressive_training:
  enabled: true

  # Stage 0: OCR Pretraining
  # Purpose: Train OCR model on license plate data before SR training
  # This ensures OCR can provide meaningful guidance to the generator
  stage0:
    name: "pretrain"
    epochs: 150   # Increased: OCR needs more time to learn from scratch
    lr: 0.001  # Increased from 0.0001 for faster convergence
    loss_components: ["ocr"]
    freeze_ocr: false
    update_confusion: false

  # Stage 1: Warm-up (L1 loss only)
  # Purpose: Stabilize network before introducing complex losses
  stage1:
    name: "warmup"
    epochs: 30    # Increased: More warm-up for stability
    lr: 0.0001
    loss_components: ["l1"]
    freeze_ocr: true
    update_confusion: false

  # Stage 2: LCOFL Training (Character-driven loss)
  # Purpose: Optimize for character recognition with frozen OCR
  stage2:
    name: "lcofl"
    epochs: 300   # Increased: model was still improving at epoch 60+
    lr: 0.0001
    loss_components: ["l1", "lcofl"]
    freeze_ocr: true
    update_confusion: true

  # Stage 3: Fine-tuning (Joint optimization)
  # Purpose: Refine with unfrozen OCR for co-adaptation
  stage3:
    name: "finetune"
    epochs: 150   # Increased: joint training needs more time
    lr: 0.00001   # Lower LR for joint training
    loss_components: ["l1", "lcofl"]
    freeze_ocr: false
    update_confusion: true

# TensorBoard Configuration
tensorboard:
  enabled: true
  # Logs are stored in <save_dir>/logs subdirectory
  log_dir: "logs"
  port: 6007

  # Logging intervals
  log_interval: 10      # Log scalars every N steps
  log_images_every: 5   # Log images every N epochs
  log_histograms_every: 10  # Log histograms every N epochs

  # Maximum images to log per batch
  max_images: 16

# Evaluation settings
evaluation:
  # Batch size for evaluation (reduced from 32 to 16 due to larger input images)
  batch_size: 16

  # Metrics to compute
  metrics:
    - "psnr"        # Peak Signal-to-Noise Ratio
    - "ssim"        # Structural Similarity Index
    - "char_acc"    # Character-level accuracy
    - "word_acc"    # Word-level (full plate) accuracy

  # Number of visualization samples
  num_vis_samples: 10

  # Visualization save directory
  vis_dir: "results/visualizations"
